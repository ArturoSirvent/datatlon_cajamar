{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a48cb8-fa8d-447a-a5b2-bd9de3fa760d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1> Script predicción</h1> \n",
    "<h2> The Backpropagation Boyz </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16646e1-e3e4-40ce-a05c-6ab4de75b49d",
   "metadata": {},
   "source": [
    "# Librerias y funciones  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ea5dbd-ceae-4234-acf8-d5f9519bf457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os \n",
    "import tensorflow as tf\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#clustering\n",
    "from scipy.cluster.hierarchy import complete,single, fcluster,dendrogram\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#esta funcion coge series como input y las secciona, dando n puntos iniciales (feature) y los m siguientes (labels)\n",
    "\n",
    "def window(data_big,size_input,size_output=None,data_aux=None):\n",
    "  if size_output is not None:\n",
    "    #esto para implementar que se devuelvan ventanas mas grandes\n",
    "    features=[]\n",
    "    labels=[]\n",
    "    #if data_aux is not None:\n",
    "      #data_aux=data_aux.T\n",
    "\n",
    "    for i in range(0,data_big.shape[0]):\n",
    "      data=data_big[i]\n",
    "      for j in range(data_big.shape[1] - size_input -size_output):\n",
    "        if data_aux is not None:\n",
    "          data_aux_slice=data_aux[j:(j+size_input),:]\n",
    "          features.append(np.hstack([data[j:(j+size_input)][...,np.newaxis],data_aux_slice]))\n",
    "        else:\n",
    "          features.append(data[j:(j+size_input)])\n",
    "        labels.append(data[(j+size_input):(j+size_input+size_output)])\n",
    "  else:\n",
    "    features=[]\n",
    "    labels=[]\n",
    "    for i in range(0,data_big.shape[0]):\n",
    "      data=data_big[i]\n",
    "      for j in range(data_big.shape[1] - size_input -1):\n",
    "        if data_aux is not None:\n",
    "          data_aux_slice=data_aux[j:(j+size_input),:]\n",
    "          features.append(np.hstack([data[j:(j+size_input)][...,np.newaxis],data_aux_slice]))\n",
    "        else:\n",
    "          features.append(data[j:(j+size_input)])\n",
    "        labels.append(data[j+size_input+1])\n",
    "  return np.array(features),np.array(labels)  \n",
    "\n",
    "\n",
    "\n",
    "#funcion que coge una serie temporal, un modelo y va predicciendo todo lo que puede \n",
    "#si toma inputs de 20 y devuelve 7, va prediciendo asi la serie temporal (de 7 en en 7 conociendo los 20 anteriores)\n",
    "def pred_model2(model,ts,window):\n",
    "  input_size=model.input_shape[1]\n",
    "  leng=ts.shape[0]\n",
    "  preds=[]\n",
    "  for i in range(input_size,leng-window,window):\n",
    "    preds.append(model.predict(ts[(i-input_size):i][np.newaxis,...])[0])\n",
    "  return np.array(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1708c-43ba-4d09-ba6c-19d0e3832471",
   "metadata": {},
   "source": [
    "# Carga y preprocesado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177fec90-c705-43c5-863d-999ee929b22b",
   "metadata": {},
   "source": [
    "Comenzamos ordenando las muestras del fichero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02671ae9-67f5-4b23-9aba-6bce712c9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sort Modelar_UH2022.txt > Modelar_UH2022_sorted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defb669c-cfd8-4df2-91ba-6d9ba66407a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0|2019-02-01 00:39:36|331710|0|0|0\n",
      "0|2019-02-01 01:39:36|331710|0|0|0\n",
      "0|2019-02-01 02:39:35|331710|0|0|0\n",
      "0|2019-02-01 03:39:35|331710|0|0|0\n",
      "0|2019-02-01 04:39:35|331710|0|0|0\n",
      "0|2019-02-01 05:39:35|331710|0|0|0\n",
      "0|2019-02-01 06:39:35|331710|0|0|0\n",
      "0|2019-02-01 07:39:35|331729|0|19|0\n",
      "0|2019-02-01 08:39:35|331765|0|36|0\n",
      "0|2019-02-01 09:39:35|331765|0|0|0\n"
     ]
    }
   ],
   "source": [
    "!head Modelar_UH2022_sorted.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856348c6-14a8-4d18-95d1-ae2412824494",
   "metadata": {},
   "source": [
    "La cabecera se ha quedado al final, vamos a moverla al principio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13190850-4d2d-4bc3-ad12-1f508312ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed '1h;1d;$!H;$!d;G' Modelar_UH2022_sorted.txt > tmp.txt; mv tmp.txt Modelar_UH2022_sorted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b3d50ac-a97f-47d3-888a-14d6427b21b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID|SAMPLETIME|READINGINTEGER|READINGTHOUSANDTH|DELTAINTEGER|DELTATHOUSANDTH\n",
      "0|2019-02-01 00:39:36|331710|0|0|0\n",
      "0|2019-02-01 01:39:36|331710|0|0|0\n",
      "0|2019-02-01 02:39:35|331710|0|0|0\n",
      "0|2019-02-01 03:39:35|331710|0|0|0\n",
      "0|2019-02-01 04:39:35|331710|0|0|0\n",
      "0|2019-02-01 05:39:35|331710|0|0|0\n",
      "0|2019-02-01 06:39:35|331710|0|0|0\n",
      "0|2019-02-01 07:39:35|331729|0|19|0\n",
      "0|2019-02-01 08:39:35|331765|0|36|0\n"
     ]
    }
   ],
   "source": [
    "!head Modelar_UH2022_sorted.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e56ce03-d740-41bf-8a8b-97b15767c9b8",
   "metadata": {},
   "source": [
    "No nos interesan los datos de cada hora, vamos a agregarlos para tener la información diaria de cada deposito. Asimismo, tendremos en cuenta un solo valor sin decimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "714b1929-51dd-4354-9ed6-245981a084ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'Modelar_UH2022_agg.txt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm Modelar_UH2022_agg.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5eccc9f-1e26-47f9-9fe1-593d95702739",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open('Modelar_UH2022_sorted.txt', 'r')\n",
    "file2 = open('Modelar_UH2022_agg.txt', 'a')\n",
    "iden_pre = \"\"\n",
    "curr_delta = 0\n",
    "curr_reading = 0\n",
    "\n",
    "for i, line in enumerate(file1.readlines()):\n",
    "    if i != 0:\n",
    "        iden, content  = line.split()\n",
    "        content = content.split('|')\n",
    "\n",
    "        if '' in content: content = ['0' if c == '' else c for c in content]\n",
    "\n",
    "        if iden != iden_pre and i!= 1:\n",
    "\n",
    "            file2.write(iden_pre+'|'+ str(curr_reading)+'|'+str(curr_delta)+'\\n')\n",
    "            curr_delta = 0\n",
    "\n",
    "            \n",
    "        curr_reading = int(content[1])*100 + int(content[2])*(10**(2-len(content[2])))\n",
    "\n",
    "        curr_delta += int(content[3])*100 + int(content[4])*(10**(2-len(content[2])))\n",
    "\n",
    "        iden_pre = iden\n",
    "\n",
    "    else:\n",
    "        file2.write('ID|SAMPLETIME|READING|DELTA\\n')\n",
    "\n",
    "file1.close()\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cfcfdf5-2c78-45dd-8548-0a7671109bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm Modelar_UH2022_sorted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f49f116-abea-4329-8069-2d688bfd5d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  SAMPLETIME   READING  DELTA\n",
      "0   0  2019-02-01  33195300  24300\n",
      "1   0  2019-02-02  33218900  23600\n",
      "2   0  2019-02-03  33252400  33500\n",
      "3   0  2019-02-04  33277600  25200\n",
      "4   0  2019-02-05  33299600  22000\n"
     ]
    }
   ],
   "source": [
    "datos = pd.read_csv(\"Modelar_UH2022_agg.txt\", sep='|')\n",
    "print(datos.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ecf5e52-cd8c-4889-ae89-53a4ca0a9f5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "array type dtype('O') not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_346/360991335.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#vamos a suavizar todo y a escalarlo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlectura\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata_pre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/scipy/ndimage/_filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[0m\u001b[1;32m    343\u001b[0m                               mode, cval, truncate)\n\u001b[1;32m    344\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/scipy/ndimage/_filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# Since we are calling correlate, not convolve, revert the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gaussian_kernel1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/scipy/ndimage/_filters.py\u001b[0m in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    131\u001b[0m                          '(len(weights)-1) // 2')\n\u001b[1;32m    132\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _nd_image.correlate1d(input, weights, axis, output, mode, cval,\n\u001b[0m\u001b[1;32m    134\u001b[0m                           origin)\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: array type dtype('O') not supported"
     ]
    }
   ],
   "source": [
    "lectura = datos.iloc[:,1:].fillna(0,inplace=False).to_numpy().T\n",
    "\n",
    "#vamos a suavizar todo y a escalarlo\n",
    "data_filtered = ndimage.gaussian_filter(lectura,[0,3],0)\n",
    "scaler=MinMaxScaler()\n",
    "data_pre=scaler.fit_transform(data_filtered.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11945ac-40f4-4786-ac88-1e43a42bf80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de71a708-2ad5-444d-a395-36512c374aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
